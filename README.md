# Text Summarization based on LLM

In this notebook we are addressing some hot topics related to Large Language Models (LLMs). 

As you can notice above, there are two notebooks for now, one addressing prompt engineering, including zero-shot, and few-shot examples for text summarization. The other notebook is explaining how to apply fine-tuning specifically Parameter Efficient Fine-Tuning (PEFT) by applying Low-Rank Adaptation (LoRA).


**Note: This notebook which can be run through google colab is using hugging-face and a well known LLM model named "google/flan-t5-base".**
